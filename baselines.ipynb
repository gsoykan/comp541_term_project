{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"main.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_path = \"/Users/gurkansoykan/Desktop/ms-kuis20/projects/cloned-DLC-repo/examples/openfield-Pranav-2018-10-30/labeled-data/m4s1/img0000.png\"\n",
    "image_folder_path = \"/Users/gurkansoykan/Desktop/ms-kuis20/projects/cloned-DLC-repo/examples/openfield-Pranav-2018-10-30/labeled-data/m4s1\"\n",
    "label_data_path = \"/Users/gurkansoykan/Desktop/ms-kuis20/projects/cloned-DLC-repo/examples/openfield-Pranav-2018-10-30/labeled-data/m4s1/CollectedData_Pranav.csv\"\n",
    "image_dim_x = 640\n",
    "image_dim_y = 480\n",
    "number_of_categories = 4\n",
    "minibatch_size = 16\n",
    "test_set_size = 16\n",
    "dev_set_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[0.9019608 1.0 0.09803922; 0.9019608 0.0 0.09803922; … ; 1.0 0.09411765 0.19607843; 1.0 0.09803922 0.19607843]\n",
       "\n",
       "Float32[0.27450982 0.28235295 0.27450982; 0.27450982 0.2784314 0.27450982; … ; 0.28235295 0.2784314 0.27450982; 0.28235295 0.27450982 0.27450982]\n",
       "\n",
       "Float32[0.27058825 0.2784314 0.26666668; 0.27058825 0.2784314 0.26666668; … ; 0.2784314 0.2784314 0.27058825; 0.2784314 0.26666668 0.27058825]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.101960786 0.101960786 0.101960786; 0.101960786 0.101960786 0.101960786; … ; 0.101960786 0.101960786 0.101960786; 0.101960786 0.101960786 0.101960786]\n",
       "\n",
       "Float32[0.101960786 0.101960786 0.101960786; 0.101960786 0.105882354 0.101960786; … ; 0.101960786 0.101960786 0.105882354; 0.101960786 0.101960786 0.105882354]\n",
       "\n",
       "Float32[0.101960786 0.101960786 0.101960786; 0.101960786 0.101960786 0.101960786; … ; 0.101960786 0.105882354 0.101960786; 0.101960786 0.101960786 0.101960786]\n",
       "\n",
       "Float32[0.09411765 0.4 0.4; 0.09411765 0.09411765 0.4; … ; 0.4 0.7490196 0.7490196; 0.4 0.4 0.7490196]\n",
       "\n",
       "Float32[0.25882354 0.27450982 0.27058825; 0.25882354 0.27450982 0.27058825; … ; 0.27450982 0.27450982 0.27058825; 0.27450982 0.27058825 0.27058825]\n",
       "\n",
       "Float32[0.26666668 0.28235295 0.28235295; 0.26666668 0.2784314 0.28235295; … ; 0.28235295 0.28235295 0.2627451; 0.28235295 0.28235295 0.2627451]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.10980392 0.105882354 0.105882354; 0.10980392 0.101960786 0.105882354; … ; 0.105882354 0.11372549 0.10980392; 0.105882354 0.105882354 0.10980392]\n",
       "\n",
       "Float32[0.11372549 0.11372549 0.11372549; 0.11372549 0.11372549 0.11372549; … ; 0.11372549 0.10980392 0.11372549; 0.11372549 0.11372549 0.11372549]\n",
       "\n",
       "Float32[0.11372549 0.11372549 0.11372549; 0.11372549 0.11372549 0.11372549; … ; 0.11372549 0.11372549 0.11372549; 0.11372549 0.11372549 0.11372549]\n",
       "\n",
       "Float32[0.9843137 0.3254902 0.3254902; 0.9843137 0.9843137 0.3254902; … ; 0.3254902 0.654902 0.654902; 0.3254902 0.3254902 0.654902]\n",
       "\n",
       "Float32[0.27058825 0.28627452 0.2784314; 0.27058825 0.27450982 0.2784314; … ; 0.28627452 0.27450982 0.27058825; 0.28627452 0.2784314 0.27058825]\n",
       "\n",
       "Float32[0.2627451 0.2784314 0.27450982; 0.2627451 0.2784314 0.27450982; … ; 0.2784314 0.27058825 0.26666668; 0.2784314 0.27450982 0.26666668]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.11764706 0.11764706 0.11372549; 0.11764706 0.11372549 0.11372549; … ; 0.11764706 0.10980392 0.11764706; 0.11764706 0.11372549 0.11764706]\n",
       "\n",
       "Float32[0.11764706 0.12156863 0.1254902; 0.11764706 0.12156863 0.1254902; … ; 0.12156863 0.12941177 0.12156863; 0.12156863 0.1254902 0.12156863]\n",
       "\n",
       "Float32[0.12941177 0.12941177 0.12941177; 0.12941177 0.1254902 0.12941177; … ; 0.12941177 0.13333334 0.13725491; 0.12941177 0.12941177 0.13725491]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.32156864 0.31764707 0.30980393; 0.32156864 0.31764707 0.30980393; … ; 0.31764707 0.30980393 0.30980393; 0.31764707 0.30980393 0.30980393]\n",
       "\n",
       "Float32[0.32156864 0.3254902 0.32156864; 0.32156864 0.3254902 0.32156864; … ; 0.3254902 0.32156864 0.31764707; 0.3254902 0.32156864 0.31764707]\n",
       "\n",
       "Float32[0.32941177 0.32156864 0.33333334; 0.32941177 0.3137255 0.33333334; … ; 0.32156864 0.32941177 0.31764707; 0.32156864 0.33333334 0.31764707]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.2 0.20392157 0.19607843; 0.2 0.19607843 0.19607843; … ; 0.20392157 0.2 0.20784314; 0.20392157 0.19607843 0.20784314]\n",
       "\n",
       "Float32[0.19607843 0.19215687 0.1882353; 0.19607843 0.19215687 0.1882353; … ; 0.19215687 0.19215687 0.19607843; 0.19215687 0.1882353 0.19607843]\n",
       "\n",
       "Float32[0.1882353 0.18431373 0.18431373; 0.1882353 0.18039216 0.18431373; … ; 0.18431373 0.18039216 0.18431373; 0.18431373 0.18431373 0.18431373]\n",
       "\n",
       "Float32[0.32941177 0.32941177 0.3254902; 0.32941177 0.3254902 0.3254902; … ; 0.32941177 0.3137255 0.3254902; 0.32941177 0.3254902 0.3254902]\n",
       "\n",
       "Float32[0.32156864 0.3137255 0.32156864; 0.32156864 0.31764707 0.32156864; … ; 0.3137255 0.31764707 0.3137255; 0.3137255 0.32156864 0.3137255]\n",
       "\n",
       "Float32[0.3254902 0.3254902 0.32156864; 0.3254902 0.32156864 0.32156864; … ; 0.3254902 0.3254902 0.32941177; 0.3254902 0.32156864 0.32941177]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.20392157 0.20392157 0.19607843; 0.20392157 0.2 0.19607843; … ; 0.20392157 0.19607843 0.19607843; 0.20392157 0.19607843 0.19607843]\n",
       "\n",
       "Float32[0.2 0.19607843 0.19607843; 0.2 0.1882353 0.19607843; … ; 0.19607843 0.19607843 0.19607843; 0.19607843 0.19607843 0.19607843]\n",
       "\n",
       "Float32[0.18431373 0.18431373 0.18431373; 0.18431373 0.18431373 0.18431373; … ; 0.18431373 0.18431373 0.18039216; 0.18431373 0.18431373 0.18039216]\n",
       "\n",
       "Float32[0.32156864 0.32156864 0.3254902; 0.32156864 0.31764707 0.3254902; … ; 0.32156864 0.31764707 0.31764707; 0.32156864 0.3254902 0.31764707]\n",
       "\n",
       "Float32[0.31764707 0.32941177 0.31764707; 0.31764707 0.32156864 0.31764707; … ; 0.32941177 0.31764707 0.31764707; 0.32941177 0.31764707 0.31764707]\n",
       "\n",
       "Float32[0.3137255 0.3254902 0.31764707; 0.3137255 0.3137255 0.31764707; … ; 0.3254902 0.31764707 0.3137255; 0.3254902 0.31764707 0.3137255]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.19607843 0.19607843 0.19607843; 0.19607843 0.20392157 0.19607843; … ; 0.19607843 0.19607843 0.2; 0.19607843 0.19607843 0.2]\n",
       "\n",
       "Float32[0.19607843 0.2 0.2; 0.19607843 0.20392157 0.2; … ; 0.2 0.19215687 0.19215687; 0.2 0.2 0.19215687]\n",
       "\n",
       "Float32[0.1882353 0.18039216 0.18039216; 0.1882353 0.18431373 0.18039216; … ; 0.18039216 0.18431373 0.18431373; 0.18039216 0.18039216 0.18431373], Float32[0.033626564 0.044835936 … 0.14972031 0.1617297; 0.552975 0.85935414 … 0.38430834 0.81665415; … ; 0.05524375 0.20896718 … 0.15052031 0.14491563; 0.8988521 0.91059583 … 0.85188127 0.40032086])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = read_all_data(label_data_path, image_dim_x, image_dim_y, number_of_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16)\n",
      "(8, 16)\n",
      "(8, 84)\n"
     ]
    }
   ],
   "source": [
    "# TODO: improve this reshaping process\n",
    "reshaped_X = reshape(X, (640, 480, 3, 116))\n",
    "#reshaped_Y = reshape(Y, (640 * 480, 116 ))\n",
    "reshaped_Y = reshape(Y, (8, 116 ))\n",
    "\n",
    "x_train = reshaped_X[:,:,:, test_set_size + dev_set_size + 1 : end]\n",
    "x_dev = reshaped_X[:,:,:, test_set_size + 1: test_set_size + dev_set_size]\n",
    "x_test = reshaped_X[:,:,:, begin : test_set_size ]\n",
    "\n",
    "y_train = reshaped_Y[:, test_set_size + dev_set_size + 1: end]\n",
    "y_dev = reshaped_Y[:, test_set_size + 1 : test_set_size + dev_set_size]\n",
    "y_test = reshaped_Y[:, begin : test_set_size ]\n",
    "\n",
    "println(size(y_test))\n",
    "println(size(y_dev))\n",
    "println(size(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Knet.Train20.Data{Tuple{Array{Float32,N} where N,Array{Float32,N} where N}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrn = minibatch(x_train, y_train, minibatch_size; xsize = (image_dim_x, image_dim_y, 3, :))\n",
    "dtst = dtrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Conv; w; b; f; p; end\n",
    "(c::Conv)(x) = c.f.(pool(conv4(c.w, dropout(x,c.p)) .+ c.b))\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss(w,x,y) = sumabs2(y - predict(w,x)) / size(y,2)\n",
    "function loss(x,y) \n",
    "    sum(abs2, y - x) / size(y, 2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Chain\n",
    "    layers\n",
    "    Chain(layers...) = new(layers)\n",
    "end\n",
    "(c::Chain)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "(c::Chain)(x,y) = loss(c(x), y)\n",
    "(c::Chain)(d::Knet.Data) = mean(c(x,y) for (x,y) in d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{String,1}:\n",
       " \"5×5×3×20 Param{Array{Float32,4}}\"\n",
       " \"5×5×20×50 Param{Array{Float32,4}}\"\n",
       " \"100×918450 Param{Array{Float32,2}}\"\n",
       " \"8×100 Param{Array{Float32,2}}\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet =   Chain(Conv(5,5,3,20), \n",
    "                Conv(5,5,20,50), \n",
    "                Dense(918450,100,pdrop=0.3), \n",
    "                Dense(100,8,sigm,pdrop=0.3))\n",
    "summary.(l.w for l in lenet.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████████████┫ [100.00%, 5/5, 00:43/00:43, 8.57s/i] \n"
     ]
    }
   ],
   "source": [
    "progress!(adam(lenet, ncycle(dtrn,1), lr=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.598914\n",
      "0.13380325\n",
      "0.45890108\n",
      "Dict{Any,Any}(\"train-loss\" => 1.598914f0,\"dev-loss\" => 0.13380325f0,\"test-loss\" => 0.45890108f0)\n"
     ]
    }
   ],
   "source": [
    "lenet_losses = compute_loss_for_sets(lenet, [(\"train\", x_train, y_train), (\"dev\", x_dev, y_dev), (\"test\", x_test, y_test)])\n",
    "println(lenet_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict{Any,Any}(\"train-accuracy-mae\" => 0.33493066f0,\"test-accuracy-mae\" => 0.19958472f0,\"dev-accuracy-mae\" => 0.11287144f0)\n"
     ]
    }
   ],
   "source": [
    "lenet_accuracies = compute_accuracy_for_sets(lenet, [(\"train\", x_train, y_train), (\"dev\", x_dev, y_dev), (\"test\", x_test, y_test)])\n",
    "println(lenet_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{String,1}:\n",
       " \"5×5×3×8 Param{Array{Float32,4}}\"\n",
       " \"8×605472 Param{Array{Float32,2}}\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_net =   Chain(Conv(5,5,3,8), \n",
    "            Dense(605472,8,sigm,pdrop=0.1))\n",
    "summary.(l.w for l in basic_net.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mytrain! (generic function with 4 methods)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/denizyuret/Knet.jl/blob/master/tutorial/50.cnn.ipynb can also be checked for trainresults\n",
    "function mytrain!(model, train_data, test_data,\n",
    "                  period::Int=1, iters::Int=2, learning_rate=0.005) \n",
    "    total_progress_count = iters/period\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    push!(test_loss,  model(test_data))\n",
    "    push!(train_loss,  model(train_data))\n",
    "    for (i, _) in enumerate(sgd((x, y) -> model(x, y), cycle(train_data), lr=learning_rate))\n",
    "        current_iter = i\n",
    "        if current_iter > iters \n",
    "            break\n",
    "        end\n",
    "        println(\"current iteration: $current_iter\")\n",
    "        if current_iter % period == 0 \n",
    "            push!(test_loss,  model(test_data))\n",
    "            push!(train_loss,  model(train_data))\n",
    "        end\n",
    "    end    \n",
    "    return 0:period:iters, train_loss, test_loss\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#progress!(sgd(basic_net, ncycle(dtrn,1), lr=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration: 1\n",
      "current iteration: 2\n",
      "current iteration: 3\n",
      "current iteration: 4\n",
      "current iteration: 5\n",
      "current iteration: 6\n",
      "current iteration: 7\n",
      "current iteration: 8\n",
      "current iteration: 9\n"
     ]
    }
   ],
   "source": [
    "iters, trnloss, tstloss = @time mytrain!(basic_net, dtrn, dtst, 1, 10)\n",
    "plot(iters, trnloss, label=\"train\", xlabel=\"iterations\", ylabel=\"loss\")\n",
    "plot!(iters, tstloss, label=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.598131\n",
      "0.1337498\n",
      "0.4557367\n",
      "Dict{Any,Any}(\"train-loss\" => 1.598131f0,\"dev-loss\" => 0.1337498f0,\"test-loss\" => 0.4557367f0)\n"
     ]
    }
   ],
   "source": [
    "basic_net_losses = @time compute_loss_for_sets(basic_net, [(\"train\", x_train, y_train), (\"dev\", x_dev, y_dev), (\"test\", x_test, y_test)])\n",
    "println(basic_net_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict{Any,Any}(\"train-accuracy-mae\" => 0.33483478f0,\"test-accuracy-mae\" => 0.19900721f0,\"dev-accuracy-mae\" => 0.112844065f0)\n"
     ]
    }
   ],
   "source": [
    "basic_net_accuracies = @time compute_accuracy_for_sets(basic_net, [(\"train\", x_train, y_train), (\"dev\", x_dev, y_dev), (\"test\", x_test, y_test)])\n",
    "println(basic_net_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
