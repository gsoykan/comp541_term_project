{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"https://nextjournal.com/data/QmXNbi2LE7u6yBdBXaQ9E2zGb48FELg3TxjrLiPKBmdvZc?filename=Qat.jpg&content-type=image/jpeg\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file_path = \"/home/gsoykan/Desktop/comp541/comp541_term_project/results/imagenet-resnet-152-dag.mat\"\n",
    "cat_img_url = \"https://nextjournal.com/data/QmXNbi2LE7u6yBdBXaQ9E2zGb48FELg3TxjrLiPKBmdvZc?filename=Qat.jpg&content-type=image/jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nextjournal.com/mpd/image-classification-with-knet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_headless_resnet_from_weights (generic function with 1 method)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MAT, OffsetArrays, FFTViews, ArgParse, Images, Knet, ImageMagick\n",
    "include(\"modular.resnet.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "atype = CUDA.functional() ? KnetArray{Float32} : Array{Float32}\n",
    "Knet.atype() = atype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_params (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_params(params, atype)\n",
    "    len = length(params[\"value\"])\n",
    "    ws, ms = [], []\n",
    "    for k = 1:len\n",
    "        name = params[\"name\"][k]\n",
    "        value = convert(Array{Float32}, params[\"value\"][k])\n",
    "\n",
    "        if endswith(name, \"moments\")\n",
    "            push!(ms, reshape(value[:,1], (1,1,size(value,1),1)))\n",
    "            push!(ms, reshape(value[:,2], (1,1,size(value,1),1)))\n",
    "        elseif startswith(name, \"bn\")\n",
    "            push!(ws, reshape(value, (1,1,length(value),1)))\n",
    "        elseif startswith(name, \"fc\") && endswith(name, \"filter\")\n",
    "            push!(ws, transpose(reshape(value,(size(value,3),size(value,4)))))\n",
    "        elseif startswith(name, \"conv\") && endswith(name, \"bias\")\n",
    "            push!(ws, reshape(value, (1,1,length(value),1)))\n",
    "        else\n",
    "            push!(ws, value)\n",
    "        end\n",
    "    end\n",
    "    map(wi->convert(atype, wi), ws),\n",
    "    map(mi->convert(atype, mi), ms)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From vgg.jl\n",
    "function data(img, averageImage)\n",
    "    if occursin(\"://\",img)\n",
    "        @info \"Downloading $img\"\n",
    "        img = download(img)\n",
    "    end\n",
    "    a0 = load(img)\n",
    "    new_size = ntuple(i->div(size(a0,i)*224,minimum(size(a0))),2)\n",
    "    a1 = Images.imresize(a0, new_size)\n",
    "    i1 = div(size(a1,1)-224,2)\n",
    "    j1 = div(size(a1,2)-224,2)\n",
    "    b1 = a1[i1+1:i1+224,j1+1:j1+224]\n",
    "    c1 = permutedims(channelview(b1), (3,2,1))\n",
    "    d1 = convert(Array{Float32}, c1)\n",
    "    e1 = reshape(d1[:,:,1:3], (224,224,3,1))\n",
    "    f1 = (255 * e1 .- averageImage)\n",
    "    g1 = permutedims(f1, [2,1,3,4])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batchnorm (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch Normalization Layer\n",
    "# works both for convolutional and fully connected layers\n",
    "# mode, 0=>train, 1=>test\n",
    "function batchnorm(w, x, ms; mode=1, epsilon=1e-5)\n",
    "    mu, sigma = nothing, nothing\n",
    "    if mode == 0\n",
    "        d = ndims(x) == 4 ? (1,2,4) : (2,)\n",
    "        s = prod(size(x,d...))\n",
    "        mu = sum(x,d) / s\n",
    "        x0 = x .- mu\n",
    "        x1 = x0 .* x0\n",
    "        sigma = sqrt(epsilon + (sum(x1, d)) / s)\n",
    "    elseif mode == 1\n",
    "        mu = popfirst!(ms)\n",
    "        sigma = popfirst!(ms)\n",
    "    end\n",
    "\n",
    "    # we need getval in backpropagation\n",
    "    push!(ms, AutoGrad.value(mu), AutoGrad.value(sigma))\n",
    "    xhat = (x.-mu) ./ sigma\n",
    "    return w[1] .* xhat .+ w[2]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reslayerx0 (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reslayerx0(w,x,ms; padding=0, stride=1, mode=1)\n",
    "    b  = conv4(w[1],x; padding=padding, stride=stride)\n",
    "    bx = batchnorm(w[2:3],b,ms; mode=mode)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reslayerx1 (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reslayerx1(w,x,ms; padding=0, stride=1, mode=1)\n",
    "    relu.(reslayerx0(w,x,ms; padding=padding, stride=stride, mode=mode))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reslayerx2 (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reslayerx2(w,x,ms; pads=[0,1,0], strides=[1,1,1], mode=1)\n",
    "    ba = reslayerx1(w[1:3],x,ms; padding=pads[1], stride=strides[1], mode=mode)\n",
    "    bb = reslayerx1(w[4:6],ba,ms; padding=pads[2], stride=strides[2], mode=mode)\n",
    "    bc = reslayerx0(w[7:9],bb,ms; padding=pads[3], stride=strides[3], mode=mode)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reslayerx3 (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reslayerx3(w,x,ms; pads=[0,0,1,0], strides=[2,2,1,1], mode=1) # 12\n",
    "    a = reslayerx0(w[1:3],x,ms; stride=strides[1], padding=pads[1], mode=mode)\n",
    "    b = reslayerx2(w[4:12],x,ms; strides=strides[2:4], pads=pads[2:4], mode=mode)\n",
    "    relu.(a .+ b)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reslayerx4 (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reslayerx4(w,x,ms; pads=[0,1,0], strides=[1,1,1], mode=1)\n",
    "    relu.(x .+ reslayerx2(w,x,ms; pads=pads, strides=strides, mode=mode))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reslayerx5 (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reslayerx5(w,x,ms; strides=[2,2,1,1], mode=1)\n",
    "    x = reslayerx3(w[1:12],x,ms; strides=strides, mode=mode)\n",
    "    for k = 13:9:length(w)\n",
    "        x = reslayerx4(w[k:k+8],x,ms; mode=mode)\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resnet152 (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mode, 0=>train, 1=>test\n",
    "function resnet152(w,x,ms; mode=1)\n",
    "    # layer 1\n",
    "    conv1 = reslayerx1(w[1:3],x,ms; padding=3, stride=2, mode=mode)\n",
    "    pool1 = pool(conv1; window=3, stride=2)\n",
    "\n",
    "    # layer 2,3,4,5\n",
    "    r2 = reslayerx5(w[4:33], pool1, ms; strides=[1,1,1,1], mode=mode)\n",
    "    r3 = reslayerx5(w[34:108], r2, ms; mode=mode)\n",
    "    r4 = reslayerx5(w[109:435], r3, ms; mode=mode)\n",
    "    r5 = reslayerx5(w[436:465], r4, ms; mode=mode)\n",
    "\n",
    "    # fully connected layer\n",
    "    pool5  = pool(r5; stride=1, window=7, mode=2)\n",
    "    fc1000 = w[466] * mat(pool5) .+ w[467]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Symbol,Any} with 4 entries:\n",
       "  :atype => KnetArray{Float32,N} where N\n",
       "  :top   => 10\n",
       "  :image => \"https://nextjournal.com/data/QmXNbi2LE7u6yBdBXaQ9E2zGb48FELg3TxjrL…\n",
       "  :model => \"/home/gsoykan/Desktop/comp541/comp541_term_project/results/imagene…"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = Dict(\n",
    "  :atype => KnetArray{Float32},\n",
    "  :model => model_file_path,\n",
    "  :image => cat_img_url,\n",
    "  :top   => 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(o)\n",
    "\t@info \"Reading $(o[:model])\"\n",
    "\tmodel = matread(abspath(o[:model]))\n",
    "\tavgimg = model[\"meta\"][\"normalization\"][\"averageImage\"]\n",
    "\tavgimg = convert(Array{Float32}, avgimg)\n",
    "\tdescription = model[\"meta\"][\"classes\"][\"description\"]\n",
    "\tw, ms = get_params(model[\"params\"], o[:atype])\n",
    "\n",
    "\t@info \"Reading $(o[:image])\"\n",
    "\timg = data(o[:image], avgimg)\n",
    "\timg = convert(o[:atype], img)\n",
    "\n",
    "\t@info \"Classifying.\"\n",
    "\t#@time y1 = resnet152(w,img,ms)\n",
    "    modular_resnet152 = generate_resnet_from_weights(w, ms)\n",
    "    y1 = modular_resnet152(img)\n",
    "  \n",
    "  return y1, description\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(KnetArray{Float32,N} where N[K32(7,7,3,64)[2.5623413e-7⋯], K32(1,1,64,1)[0.17125425⋯], K32(1,1,64,1)[-0.9211457⋯], K32(1,1,64,256)[1.0009978e-7⋯], K32(1,1,256,1)[1.0431781⋯], K32(1,1,256,1)[-0.42354646⋯], K32(1,1,64,64)[5.7680538e-8⋯], K32(1,1,64,1)[1.3838099⋯], K32(1,1,64,1)[0.2129703⋯], K32(3,3,64,64)[-0.013626201⋯]  …  K32(1,1,512,1)[0.92608565⋯], K32(1,1,512,1)[-0.91251934⋯], K32(3,3,512,512)[-0.004375612⋯], K32(1,1,512,1)[1.0832604⋯], K32(1,1,512,1)[-0.8033409⋯], K32(1,1,512,2048)[-0.015731078⋯], K32(1,1,2048,1)[1.4361827⋯], K32(1,1,2048,1)[-1.7722093⋯], K32(1000,2048)[-0.014174754⋯], K32(1000,1)[-0.01870472⋯]], KnetArray{Float32,4}[K32(1,1,64,1)[-9.028228e-5⋯], K32(1,1,64,1)[0.005939396⋯], K32(1,1,256,1)[-0.764459⋯], K32(1,1,256,1)[0.8341639⋯], K32(1,1,64,1)[-2.0849948⋯], K32(1,1,64,1)[1.1826472⋯], K32(1,1,64,1)[-1.1165951⋯], K32(1,1,64,1)[1.0983644⋯], K32(1,1,256,1)[-0.1807499⋯], K32(1,1,256,1)[0.2596636⋯]  …  K32(1,1,512,1)[-0.39513633⋯], K32(1,1,512,1)[0.3477594⋯], K32(1,1,2048,1)[-0.018619375⋯], K32(1,1,2048,1)[0.07230469⋯], K32(1,1,512,1)[-1.0350311⋯], K32(1,1,512,1)[1.9032351⋯], K32(1,1,512,1)[-0.33744317⋯], K32(1,1,512,1)[0.31716385⋯], K32(1,1,2048,1)[-0.03702657⋯], K32(1,1,2048,1)[0.10916653⋯]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = matread(abspath(o[:model]))\n",
    "w, ms = get_params(model[\"params\"], o[:atype])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Array{KnetArray{Float32,N} where N,1}:\n",
       " K32(1,1,64,1)[0.17125425⋯]\n",
       " K32(1,1,64,1)[-0.9211457⋯]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(size(w[1:3]))\n",
    "w[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnetArray{Float32,N} where N"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knet.atype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: invalid index: :model of type Symbol",
     "output_type": "error",
     "traceback": [
      "ArgumentError: invalid index: :model of type Symbol",
      "",
      "Stacktrace:",
      " [1] to_index(::Symbol) at ./indices.jl:297",
      " [2] to_index(::CUDA.CuArray{Float32,4}, ::Symbol) at ./indices.jl:274",
      " [3] to_indices at ./indices.jl:325 [inlined]",
      " [4] to_indices at ./indices.jl:322 [inlined]",
      " [5] getindex(::CUDA.CuArray{Float32,4}, ::Symbol) at /home/gsoykan/.julia/packages/GPUArrays/jhRU7/src/host/indexing.jl:125",
      " [6] getindex(::KnetArray{Float32,4}, ::Symbol) at /home/gsoykan/.julia/packages/Knet/LdQyF/src/knetarrays/getindex.jl:39",
      " [7] top-level scope at In[73]:1",
      " [8] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "\tmodel = matread(abspath(o[:model]))\n",
    "\tavgimg = model[\"meta\"][\"normalization\"][\"averageImage\"]\n",
    "\tavgimg = convert(Array{Float32}, avgimg)\n",
    "\tdescription = model[\"meta\"][\"classes\"][\"description\"]\n",
    "\tw, ms = get_params(model[\"params\"], o[:atype])\n",
    "\t@info \"Reading $(o[:image])\"\n",
    "\timg = data(o[:image], avgimg)\n",
    "\timg = convert(o[:atype], img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResLayerX0(BatchNormLayer(K32(2,1,64,1)[0.17125425⋯], Knet.Ops20.BNMoments(0.1, nothing, nothing, K32(1,1,64,1)[-1.1165951⋯], K32(1,1,64,1)[1.0983644⋯])), P(KnetArray{Float32,4}(7,7,3,64)), 3, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_conv_0 = ResLayerX0(w[1:3], ms; padding=3, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_bnbias (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " _wsize(y) = ((1 for _=1:ndims(y)-2)..., size(y)[end-1], 1)\n",
    "_bnscale(param) = param[1:div(length(param), 2)]\n",
    "_bnbias(param) = param[div(length(param), 2)+1:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{KnetArray{Float32,N} where N,1}:\n",
       " K32(1,1,64,1)[0.17125425⋯]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bnscale(w[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1×64×1 KnetArray{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " -0.9211457\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " -1.4652015\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 2.633772\n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 62, 1] =\n",
       " 1.6320676\n",
       "\n",
       "[:, :, 63, 1] =\n",
       " 1.9162116\n",
       "\n",
       "[:, :, 64, 1] =\n",
       " 2.9234889"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bnbias(w[2:3])[begin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112×112×64×1 KnetArray{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.00155164  0.00217484  0.00252128  0.00255651  …  -0.00487571  -0.0033682\n",
       " 0.00222874  0.00303667  0.00355126  0.00359155     -0.00677657  -0.004548\n",
       " 0.00247406  0.00351398  0.00421234  0.00426079     -0.00801704  -0.0053319\n",
       " 0.00232927  0.0035016   0.00412335  0.00407446     -0.0079847   -0.00529423\n",
       " 0.00232102  0.0034754   0.00397684  0.00406086     -0.00787128  -0.00522677\n",
       " 0.00227484  0.00310577  0.00367556  0.00391136  …  -0.00778167  -0.00517022\n",
       " 0.00211593  0.00274914  0.00368213  0.00394518     -0.00771855  -0.00510506\n",
       " 0.00198451  0.00277622  0.00365969  0.00376688     -0.00771099  -0.00510244\n",
       " 0.0018812   0.00286177  0.00356199  0.00391781     -0.00776     -0.0051512\n",
       " 0.00210478  0.00324866  0.00378334  0.00404427     -0.00783995  -0.00520396\n",
       " 0.0022422   0.00328754  0.00385374  0.00421957  …  -0.00790995  -0.00525933\n",
       " 0.00232714  0.00329219  0.00414061  0.00396097     -0.00798731  -0.00531188\n",
       " 0.00211426  0.0029795   0.00364964  0.00325318     -0.00807086  -0.00537767\n",
       " ⋮                                               ⋱   ⋮           \n",
       " 0.00467288  0.00675832  0.00789763  0.00826592  …   0.010096     0.00685859\n",
       " 0.0045466   0.00662422  0.00764709  0.00788183      0.0104442    0.00698939\n",
       " 0.00458948  0.00668791  0.00777104  0.00799559      0.0105652    0.00709236\n",
       " 0.00437795  0.00638933  0.00737221  0.00776504      0.0104601    0.0070075\n",
       " 0.00449103  0.00649499  0.00753963  0.00784694      0.0102781    0.00689185\n",
       " 0.00454175  0.00661854  0.00761848  0.00803941  …   0.0100689    0.0067555\n",
       " 0.00464691  0.0067089   0.00780594  0.00832483      0.00996757   0.00669696\n",
       " 0.00476508  0.00681352  0.00786779  0.00824878      0.00982139   0.00659776\n",
       " 0.00469937  0.0067572   0.00792199  0.00841902      0.00989419   0.00665442\n",
       " 0.00489022  0.00704397  0.00833646  0.00864088      0.00994705   0.00669018\n",
       " 0.00503086  0.00723277  0.00857016  0.00874606  …   0.0100883    0.0067087\n",
       " 0.00358385  0.00489186  0.00587211  0.00593517      0.00674964   0.00425886\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 17.5188  18.4012   11.4357   12.1816  …   -29.58     -29.8315  -18.867\n",
       " 38.1162  41.2604   39.6928   41.4202      -88.5923   -88.4086  -56.6471\n",
       " 43.1322  47.0495   49.9935   48.4846     -108.084   -107.655   -68.214\n",
       " 39.6983  50.9688   51.0779   48.4703     -107.641   -107.269   -68.1879\n",
       " 37.2655  50.8071   47.2546   47.2789     -107.516   -107.426   -68.7458\n",
       " 39.7415  48.4393   43.5921   48.498   …  -106.759   -106.888   -68.5764\n",
       " 40.0377  42.7187   44.5083   51.1241     -106.047   -105.353   -67.5018\n",
       " 35.1232  37.8969   43.756    48.7366     -106.184   -104.965   -66.8362\n",
       " 31.2206  40.3497   44.1298   42.1355     -106.662   -105.649   -67.0625\n",
       " 31.4295  44.2932   40.0215   40.1533     -106.052   -105.961   -67.667\n",
       " 36.2565  46.929    44.8921   50.4109  …  -105.884   -106.151   -67.8654\n",
       " 38.0844  43.7184   48.8717   53.9843     -106.071   -106.053   -67.7089\n",
       " 38.4884  38.5491   47.975    50.3949     -106.647   -106.073   -67.6129\n",
       "  ⋮                                    ⋱                ⋮       \n",
       " 73.1141  82.8885   78.8328   83.0523  …   103.625    104.252    67.4691\n",
       " 75.9502  88.2349   86.5073   89.614       107.724    107.438    70.4576\n",
       " 73.0225  83.756    81.0863   83.8388      109.339    109.627    70.8211\n",
       " 70.3712  80.161    78.8398   80.4234      110.236    110.524    71.0259\n",
       " 72.3127  81.7148   78.929    80.9801      109.248    109.578    71.782\n",
       " 71.6268  82.571    77.5682   83.5028  …   107.322    108.166    71.0344\n",
       " 72.8569  85.5566   80.9315   83.3346      104.951    106.22     68.95\n",
       " 73.7256  87.1883   81.5925   85.7727      105.036    107.047    69.2333\n",
       " 74.2395  88.8997   83.8356   85.4382      104.662    106.472    69.3449\n",
       " 73.2689  86.3689   80.5889   83.7711      103.15     106.29     70.8626\n",
       " 74.9581  88.0711   84.3681   87.7024  …   105.531    107.009    72.3582\n",
       " 76.4531  99.2149  102.941   102.82        118.482    119.18     80.6865\n",
       "\n",
       "[:, :, 3, 1] =\n",
       "  26.2692      4.01227     -3.9373    …   -0.646951   -3.98161    -7.38037\n",
       "   2.17746     2.54596      7.65514       -2.38659     5.10879   -16.7874\n",
       "   6.34876    -1.91803    -17.6808         7.94798     2.1022     -8.74712\n",
       "  30.8914    -10.9728      27.2471         3.51781     6.83613    -6.81281\n",
       " -26.6877     21.7848      -3.62068        6.73675     5.30524    -9.18623\n",
       "  -0.258248    9.92441    -33.4253    …    6.30513     3.5904     -7.81968\n",
       "   0.275187   15.3907       4.18506        4.13321     6.81098    -9.76412\n",
       "  39.8321    -48.4255       4.32752        3.94389     7.41014    -4.76156\n",
       "  -0.904774   -0.0973639    7.51636        3.80381     7.5851     -9.52591\n",
       "  14.6411     11.8955      -6.96332        5.6589      2.77952    -5.34132\n",
       " -36.9682     27.8193      18.6245    …    8.84367     5.95472   -11.5917\n",
       "  30.9836    -26.5685     -38.6983         2.33296     2.94814    -2.96342\n",
       "  12.6412      5.87944     21.8178         4.95609     5.68835   -12.9529\n",
       "   ⋮                                  ⋱                ⋮         \n",
       "  36.0064    -51.6952      36.3888    …    5.83623   -19.6915     26.0835\n",
       "  25.9373     40.1089     -38.2283       -10.5471     -4.89134     5.09205\n",
       "  -7.87669     0.14211     -3.0305         3.16624    -8.04448    27.9797\n",
       "  21.0402      1.34107     12.0283        -6.93222     3.87879     6.74456\n",
       "  34.8033    -32.033       -0.980817      -0.398633  -14.3025     21.8502\n",
       "  17.483      36.7172     -31.5563    …   -9.18157    10.6882      7.24876\n",
       "   1.76264     9.34102      4.13832      -11.0221     -3.07159    11.4104\n",
       "  36.388      -5.82479     -2.14234      -11.0953     -0.264215   14.3732\n",
       "   3.2545     21.6286      -7.91746       11.3602     -8.56123    17.849\n",
       "  28.0895    -20.7919      -4.88169        2.74972    -5.93416    13.5991\n",
       "  15.3995     13.6553      -5.1461    …  -16.9419      2.39228    11.7736\n",
       "  39.1283     10.5805     -13.9784        10.4327    -15.7805     20.686\n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 62, 1] =\n",
       "  -68.3477   -149.67     -54.1153   …  136.571     136.452    193.83\n",
       "  -67.169      71.5555    85.5871      -60.9418    -73.9592   -67.7518\n",
       "  -55.6385     65.6212    -1.73977     -31.88      -23.6638    -8.24625\n",
       "  -49.9986     79.6603   -80.13        -22.5413    -13.4423   -11.6181\n",
       "   25.0909    -49.4277    22.3728      -16.1192    -28.9836   -18.1699\n",
       "  -30.1984    -20.7839    94.8073   …  -32.7474    -29.9769    -1.33057\n",
       "  -53.7311     45.1632    63.1882      -25.5669    -17.4318    -5.61251\n",
       "  -38.2101    106.149    -62.4484      -14.6778    -19.778    -16.3811\n",
       "  -26.8583     -1.73592  -48.0845      -20.1804    -27.7186    -6.00928\n",
       "    6.07441     3.99904   25.1095      -18.4228    -22.6956    -5.24537\n",
       "  -20.5959    -68.4665    55.2425   …  -25.3857    -25.5408    -4.45028\n",
       "  -59.1798     55.7281    70.1895      -31.1903    -16.7388   -11.5961\n",
       "  -54.5257     40.3106   -45.6585      -19.8537    -17.5006    -9.35281\n",
       "    ⋮                               ⋱                ⋮        \n",
       " -103.691     129.381    -11.997    …    9.40078    47.3704     2.1818\n",
       "  -85.1998     23.9009    14.7138       16.096      36.8189    15.0637\n",
       "  -33.5683     72.5405    27.0184       30.7238     41.7419     8.31999\n",
       "  -83.2331     39.9152   -15.2839       49.7933      8.28536   23.8489\n",
       "  -83.9883    104.014     23.1724       18.0798     36.8123    24.0182\n",
       "  -83.6188     19.1742    11.4852   …   33.8024     40.0538    12.8262\n",
       "  -71.1584     54.9364    14.4025       44.9119     12.0917    19.8558\n",
       "  -65.8893     57.9101    12.1619       47.6466     14.2939    15.9012\n",
       "  -81.6084     16.3762    50.2875       13.0689     33.2342    18.871\n",
       "  -44.952      81.6482    20.057        -0.118373   42.7348    -5.55357\n",
       "  -75.846     -15.2205    21.6473   …   54.672      28.5416     9.19176\n",
       " -167.269      32.3319    14.1749      -25.1097    -11.2603   -21.3569\n",
       "\n",
       "[:, :, 63, 1] =\n",
       " 14.232    32.2701   41.5908   42.1829  …  -42.0403  -41.3256  -32.8852\n",
       " 35.1076   59.4551   72.4714   78.8303     -58.6145  -55.7448  -39.6886\n",
       " 42.7852   68.0422   87.9524   87.0309     -54.8081  -51.6431  -31.0264\n",
       " 40.4755   72.7449   89.8666   83.76       -50.8523  -49.3802  -30.2078\n",
       " 36.7935   75.0693   84.5216   82.285      -46.7505  -47.3206  -29.3848\n",
       " 37.5537   71.2456   74.3927   81.4564  …  -47.7382  -47.1502  -28.8274\n",
       " 39.9667   64.475    78.7563   82.3193     -46.435   -44.6609  -26.4755\n",
       " 37.1109   62.7755   82.5514   78.3288     -45.4814  -43.6517  -23.825\n",
       " 32.1695   63.1481   81.7112   74.832      -47.8811  -45.1253  -23.8101\n",
       " 32.1276   67.39     77.2484   77.1533     -48.183   -47.8572  -27.5253\n",
       " 33.8553   68.022    75.4913   83.38    …  -49.4713  -50.3301  -31.0201\n",
       " 39.6167   64.0625   81.251    87.6286     -51.7371  -52.7697  -33.2386\n",
       " 39.5112   60.1363   80.5799   77.7747     -54.9085  -55.4676  -36.1609\n",
       "  ⋮                                     ⋱              ⋮       \n",
       " 63.7745   98.0087  132.6     130.061   …  138.587   140.629   111.265\n",
       " 59.9352   98.0964  124.392   123.882      139.508   140.724   110.805\n",
       " 59.4101   93.2729  119.811   115.081      140.225   141.924   111.659\n",
       " 58.313    95.2217  117.878   119.605      138.803   142.461   113.144\n",
       " 63.4305   96.2678  122.563   124.235      141.51    143.546   117.652\n",
       " 61.4898  100.405   123.012   126.847   …  142.943   145.349   117.849\n",
       " 62.9552   95.561   124.336   124.297      141.333   143.283   116.278\n",
       " 65.0499  102.098   125.46    127.119      142.393   144.905   116.055\n",
       " 64.0533  102.981   131.332   130.936      141.531   144.781   117.226\n",
       " 64.4733  105.335   135.256   135.447      140.28    142.354   115.139\n",
       " 67.2959  110.766   136.787   132.003   …  142.03    145.722   116.785\n",
       " 62.1811   96.0227  114.62    113.34       120.015   126.436    96.3051\n",
       "\n",
       "[:, :, 64, 1] =\n",
       "  59.5686  125.462   18.1399  -25.7471     …  -19.2827   -22.7177   -114.036\n",
       " 121.94    192.836  -17.9756   -8.70177        -6.99235   -8.23288  -183.713\n",
       " 176.149   185.5    -23.9559   57.3117        -21.5127   -19.7909   -198.801\n",
       " 180.467   143.517   38.9981   46.8536        -21.5786   -24.6316   -198.344\n",
       " 133.959   161.832   80.5273  -26.5558        -23.3244   -26.209    -192.453\n",
       " 101.991   212.94    15.5553  -26.1932     …  -19.6899   -18.1284   -193.812\n",
       " 125.378   213.181  -70.1962   55.4822        -14.8574   -15.6723   -196.574\n",
       " 149.573   145.931  -67.2181  121.608         -22.8205   -19.2412   -191.12\n",
       " 129.565   128.223   16.6781   59.4666        -34.0904   -20.9689   -188.631\n",
       "  92.3611  159.352   91.2853  -62.4663        -37.2488   -20.1411   -195.553\n",
       "  77.5328  197.433   77.459   -38.6902     …  -32.6957   -17.6317   -203.992\n",
       " 117.21    192.327  -10.999    78.1578        -25.4517   -19.6253   -207.352\n",
       " 172.697   151.17   -55.5923  128.492         -22.9066   -26.6908   -205.378\n",
       "   ⋮                                       ⋱               ⋮        \n",
       " 343.75    289.683   18.7071   36.4273     …    9.93792   63.3756    231.038\n",
       " 341.305   302.377   29.063    41.8912         27.3008    51.1831    229.932\n",
       " 326.563   287.912   50.5388   27.5687         28.2879    34.451     248.184\n",
       " 320.324   286.236   30.4112   40.8363         15.869     40.1922    242.898\n",
       " 333.222   273.094   36.4036   21.8866          4.23068   53.8188    235.766\n",
       " 334.69    284.985   39.4676   17.9577     …    6.46449   42.5724    242.334\n",
       " 326.587   303.775   52.489     6.60896         4.62221   32.7759    244.895\n",
       " 321.401   310.514   56.8067   -0.0553598      -7.5507    48.1206    240.547\n",
       " 314.073   329.094   55.1884   -4.96529       -14.1489    55.3873    246.159\n",
       " 302.189   334.216   56.861     7.12665        -1.90343   40.15      267.799\n",
       " 307.247   351.879   45.2515   43.2339     …    5.59701    8.19241   290.856\n",
       " 277.16    340.371    9.4474   40.8386          8.26749  -22.8729    248.566"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = conv4(w[1], img; padding=3, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Knet.Ops20.BNMoments(0.1, nothing, nothing, K32(1,1,64,1)[-9.028228e-5⋯], K32(1,1,64,1)[0.005939396⋯])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   res_mean = popfirst!(ms)\n",
    "        res_variance = popfirst!(ms)\n",
    "        batch_ms = bnmoments(meaninit=res_mean, varinit=res_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Knet.Ops20.BNMoments(0.1, nothing, nothing, zeros, ones)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnmoments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mean_function not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mean_function not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[80]:3",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "f_res_mean = convert(Array{Float32}, res_mean)\n",
    "f_res_variance = convert(Array{Float32}, res_variance)\n",
    "f_batch_ms = bnmoments(meaninit=mean_function, varinit=var_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function var_function([eltype], dims...)\n",
    "   f_res_variance = convert(eltype, res_variance)\n",
    "    end\n",
    "\n",
    "function mean_function([eltype], dims...)\n",
    "    f_res_mean = convert(eltype, res_mean)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 64, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_wsize(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×1×64×1 Array{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       "  0.17125425\n",
       " -0.9211457\n",
       "\n",
       "[:, :, 2, 1] =\n",
       "  1.0912106\n",
       " -1.4652015\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.834577\n",
       " 2.633772\n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 62, 1] =\n",
       " 0.98383784\n",
       " 1.6320676\n",
       "\n",
       "[:, :, 63, 1] =\n",
       " 1.115136\n",
       " 1.9162116\n",
       "\n",
       "[:, :, 64, 1] =\n",
       " 1.2307211\n",
       " 2.9234889"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = convert(Array{Float32}, w[2])\n",
    "w3 = convert(Array{Float32}, w[3])\n",
    "vcatted_ws = vcat(w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching (::var\"#82#84\")(::Type{Float32}, ::Int64, ::Int64, ::Int64, ::Int64)\nClosest candidates are:\n  #82(::Any, ::Any) at In[71]:3",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching (::var\"#82#84\")(::Type{Float32}, ::Int64, ::Int64, ::Int64, ::Int64)\nClosest candidates are:\n  #82(::Any, ::Any) at In[71]:3",
      "",
      "Stacktrace:",
      " [1] _lazy_init!(::Knet.Ops20.BNMoments, ::KnetArray{Float32,4}) at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20/batchnorm.jl:208",
      " [2] _batchnorm4_fused(::Array{Float32,4}, ::Array{Float32,4}, ::KnetArray{Float32,4}; eps::Float64, training::Bool, cache::Knet.Ops20.BNCache, moments::Knet.Ops20.BNMoments, o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20/batchnorm.jl:162",
      " [3] #batchnorm4#180 at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20/batchnorm.jl:149 [inlined]",
      " [4] batchnorm(::KnetArray{Float32,4}, ::Knet.Ops20.BNMoments, ::Array{Float32,4}; training::Bool, o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20/batchnorm.jl:70",
      " [5] batchnorm(::KnetArray{Float32,4}, ::Knet.Ops20.BNMoments, ::Array{Float32,4}) at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20/batchnorm.jl:57",
      " [6] top-level scope at In[72]:1",
      " [7] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "batchnorm(o, f_batch_ms, vcatted_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: objects of type KnetArray{Float32,4} are not callable",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type KnetArray{Float32,4} are not callable",
      "",
      "Stacktrace:",
      " [1] _lazy_init!(::Knet.Ops20.BNMoments, ::KnetArray{Float32,4}) at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20/batchnorm.jl:208",
      " [2] _batchnorm4(::Type{T} where T, ::KnetArray{Float32,4}, ::KnetArray{Float32,4}, ::KnetArray{Float32,4}; training::Bool, cache::Knet.Ops20.BNCache, moments::Knet.Ops20.BNMoments, eps::Float64, alpha::Int64, beta::Int64, handle::Ptr{Nothing}, cache_verbose::Bool, o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20_gpu/batchnorm.jl:36",
      " [3] #batchnorm4#1 at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20_gpu/batchnorm.jl:11 [inlined]",
      " [4] batchnorm(::KnetArray{Float32,4}, ::Knet.Ops20.BNMoments, ::KnetArray{Float32,4}; training::Bool, o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20/batchnorm.jl:70",
      " [5] batchnorm(::KnetArray{Float32,4}, ::Knet.Ops20.BNMoments, ::KnetArray{Float32,4}) at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20/batchnorm.jl:57",
      " [6] (::BatchNormLayer)(::KnetArray{Float32,4}) at /home/gsoykan/Desktop/comp541/comp541_term_project/models.jl:81",
      " [7] (::ResLayerX0)(::KnetArray{Float32,4}) at /home/gsoykan/Desktop/comp541/comp541_term_project/models.jl:100",
      " [8] top-level scope at In[54]:1",
      " [9] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "res_conv_0(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Reading /home/gsoykan/Desktop/comp541/comp541_term_project/results/imagenet-resnet-152-dag.mat\n",
      "└ @ Main In[8]:2\n",
      "┌ Info: Reading https://nextjournal.com/data/QmXNbi2LE7u6yBdBXaQ9E2zGb48FELg3TxjrLiPKBmdvZc?filename=Qat.jpg&content-type=image/jpeg\n",
      "└ @ Main In[8]:9\n",
      "┌ Info: Downloading https://nextjournal.com/data/QmXNbi2LE7u6yBdBXaQ9E2zGb48FELg3TxjrLiPKBmdvZc?filename=Qat.jpg&content-type=image/jpeg\n",
      "└ @ Main In[6]:4\n",
      "┌ Info: Classifying.\n",
      "└ @ Main In[8]:13\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch(\"new dimensions (1, 1, 64, 1) must be consistent with array size 1\")",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch(\"new dimensions (1, 1, 64, 1) must be consistent with array size 1\")",
      "",
      "Stacktrace:",
      " [1] (::Base.var\"#throw_dmrsa#213\")(::NTuple{4,Int64}, ::Int64) at ./reshapedarray.jl:41",
      " [2] reshape(::Array{KnetArray{Float32,N} where N,1}, ::NTuple{4,Int64}) at ./reshapedarray.jl:45",
      " [3] batchnorm(::KnetArray{Float32,4}, ::Knet.Ops20.BNMoments, ::Array{KnetArray{Float32,N} where N,1}; training::Bool, o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20/batchnorm.jl:60",
      " [4] batchnorm(::KnetArray{Float32,4}, ::Knet.Ops20.BNMoments, ::Array{KnetArray{Float32,N} where N,1}) at /home/gsoykan/.julia/packages/Knet/LdQyF/src/ops20/batchnorm.jl:57",
      " [5] (::BatchNormLayer)(::KnetArray{Float32,4}) at /home/gsoykan/Desktop/comp541/comp541_term_project/models.jl:79",
      " [6] (::ResLayerX0)(::KnetArray{Float32,4}) at /home/gsoykan/Desktop/comp541/comp541_term_project/models.jl:98",
      " [7] (::ResLayerX1)(::KnetArray{Float32,4}) at /home/gsoykan/Desktop/comp541/comp541_term_project/models.jl:106",
      " [8] (::Chain)(::KnetArray{Float32,4}) at /home/gsoykan/Desktop/comp541/comp541_term_project/models.jl:46",
      " [9] predict(::Dict{Symbol,Any}) at ./In[8]:16",
      " [10] top-level scope at In[11]:1",
      " [11] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "y1, description = predict(o)\n",
    "   epso\n",
    "adekase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Array{Float32,1}:\n",
       " 1.6237807f-6\n",
       " 1.7950113f-6\n",
       " 3.0487963f-6\n",
       " 1.8512f-6\n",
       " 2.2960382f-6\n",
       " 9.160164f-5\n",
       " 8.271447f-5\n",
       " 4.423799f-5\n",
       " 0.0016335086\n",
       " 4.4700588f-5\n",
       " 4.778216f-5\n",
       " 1.0584847f-5\n",
       " 0.00033455592\n",
       " ⋮\n",
       " 0.00027946424\n",
       " 7.1559484f-6\n",
       " 7.852398f-5\n",
       " 8.843055f-7\n",
       " 2.2513111f-6\n",
       " 3.4196191f-6\n",
       " 5.8417627f-6\n",
       " 8.232677f-6\n",
       " 4.2582205f-6\n",
       " 1.3455667f-5\n",
       " 0.00015772587\n",
       " 0.0008228442"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = vec(Array(y1))\n",
    "s1 = sortperm(z1,rev=true)\n",
    "p1 = exp.(logp(z1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabby, tabby cat: 32.22%\n",
      "Egyptian cat: 22.96%\n",
      "tiger cat: 9.38%\n",
      "mongoose: 4.29%\n",
      "lynx, catamount: 1.95%\n",
      "bath towel: 1.41%\n",
      "prayer rug, prayer mat: 1.28%\n",
      "teddy, teddy bear: 1.24%\n",
      "great grey owl, great gray owl, Strix nebulosa: 1.03%\n",
      "guinea pig, Cavia cobaya: 1.00%\n"
     ]
    }
   ],
   "source": [
    "using Printf\n",
    "\n",
    "for ind in s1[1:o[:top]]\n",
    "  print(\"$(description[ind]): $(@sprintf(\"%.2f\",p1[ind]*100))%\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
